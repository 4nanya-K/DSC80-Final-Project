{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNht40dW_P8I",
    "outputId": "54a815cb-d15e-4c02-a122-0be84b1f3196"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCt1QY2E5BJW"
   },
   "source": [
    "# Macronutrients & Ratings: \n",
    "# Impact of High-Carbs and Low-Protein on Recipe Ratings\n",
    "\n",
    "**Name(s)**: Ananya Krishnan, John Wesley Pabalate\n",
    "\n",
    "**Website Link**: https://j0hnwesl3yyy.github.io/recipe-rating-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    },
    "id": "U_OBhvSp5BJX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "#from dsc80_utils import * # Feel free to uncomment and use this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqCArYDF5BJY"
   },
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: \n",
    "- Do high-carb, low-protein recipes receive significantly different ratings compared to other recipes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqTPwukc5BJY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pxNfkQe5BJY"
   },
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "6SYdl1zN5BJY",
    "outputId": "b113df0d-d05d-471f-ea47-5ac64c8d3884"
   },
   "outputs": [],
   "source": [
    "#JohnWesley's Directory\n",
    "#recipes = pd.read_csv('/Users/johnwesleypabalate/Desktop/dsc80-2025-wi/projects/project04/data/RAW_recipes.csv')\n",
    "\n",
    "#Ananya's Directory\n",
    "recipes = pd.read_csv('/Users/ananyakrishnan/Downloads/DSC80/projects/project04/data/RAW_recipes.csv')\n",
    "recipes.head()\n",
    "\n",
    "#Colab Directory\n",
    "# recipes = pd.read_csv('/content/RAW_recipes.csv')\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fzm4nVcb5BJY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#JohnWesley's Directory\n",
    "#reviews = pd.read_csv('/Users/johnwesleypabalate/Desktop/dsc80-2025-wi/projects/project04/data/RAW_interactions.csv')\n",
    "\n",
    "#Ananya's Directory\n",
    "reviews = pd.read_csv('../DSC80/projects/project04/data/RAW_interactions.csv')\n",
    "reviews.head()\n",
    "\n",
    "#Colab Directory\n",
    "# reviews = pd.read_csv('/content/interactions.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj3R7Gms5BJY"
   },
   "source": [
    "Let us now merge recipes and ratings into one comprehensive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q813voGP5BJZ"
   },
   "outputs": [],
   "source": [
    "recipe_ratings = recipes.merge(reviews, left_on = 'id', right_on = 'recipe_id', how=\"left\")\n",
    "recipe_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3AtXzes5BJZ"
   },
   "source": [
    "Let us replace all 0s in the ratings column with NaN values. The 0 represents no rating given, but it will influence any calculations we perform with the ratings. We also calculate the average ratings for each recipe and store it in `avg_recipe_rating`. We will then add it as a column to recipe_reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyIrGLYd5BJZ"
   },
   "outputs": [],
   "source": [
    "recipe_ratings.loc[recipe_ratings['rating'] == 0, 'rating'] = np.nan\n",
    "avg_recipe_rating = recipe_ratings.groupby('recipe_id')['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyTvTB_y5BJZ"
   },
   "outputs": [],
   "source": [
    "recipe_ratings = recipe_ratings.merge(avg_recipe_rating.reset_index().rename(columns={'rating': 'avg_rating'}), on = 'recipe_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made a copy of recipe_ratings for the purpose of using it for the Missingness and Baseline: \n",
    "merged_df = recipe_ratings.copy()\n",
    "merged_df = merged_df.drop(columns=['Unnamed: 0'])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bmih-YBt5BJZ"
   },
   "source": [
    "There are many columns not relevant to our question, so we will clean only the columns related to recipe id, nutrition information and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "herKkG_75BJZ"
   },
   "outputs": [],
   "source": [
    "recipe_ratings = recipe_ratings.drop(columns = ['recipe_id']).rename(columns = {'id': 'recipe_id'}).drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = original_df.drop(columns = ['recipe_id']).rename(columns = {'id': 'recipe_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmhddbvL5BJZ"
   },
   "source": [
    "Let us now look at the columns we have and clean them up one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_uUcZ075BJZ"
   },
   "outputs": [],
   "source": [
    "recipe_ratings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atH8uKyK5BJZ"
   },
   "source": [
    "We observe that `nutrition` actually contains strings formatted to look like lists, so let us convert it to real lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    },
    "id": "O7Hpp81j5BJZ"
   },
   "outputs": [],
   "source": [
    "recipe_ratings['nutrition'] = recipe_ratings['nutrition'].str.strip('[').str.strip(']').str.replace(\"'\", \"\").str.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ire9fL1e5BJZ"
   },
   "source": [
    "The `nutrition` column now contains lists of values. Let us separate each value into its respective category - `'calories'`, `'total_fat'`, `'sugar'`, `'sodium'`, `'protein'`, `'saturated_fat'` and `'carbohydrates'`. We can then drop the `nutrition` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDMwYimz5BJa"
   },
   "outputs": [],
   "source": [
    "categories = ['calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']\n",
    "recipe_ratings = recipe_ratings.assign(\n",
    "    **{category: pd.to_numeric(recipe_ratings['nutrition'].str[i], errors='coerce') for i, category in enumerate(categories)}\n",
    ")\n",
    "recipe_ratings = recipe_ratings.drop(columns = ['nutrition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJtJCY025BJa"
   },
   "source": [
    "Let us now look at our cleaned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.concat([original_df, recipe_ratings[['calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']]], axis=1).drop(columns = ['nutrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9pRY0ba5BJa"
   },
   "outputs": [],
   "source": [
    "recipe_ratings.isna().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5n-5JB45BJa"
   },
   "outputs": [],
   "source": [
    "recipe_ratings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XPjkiX_5BJa"
   },
   "source": [
    "The nutritional values seem to have abnormally high max values despite a reasonable mean. Let us look at the rows with high protein or high carbohydrate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwVNd8_X5BJa"
   },
   "outputs": [],
   "source": [
    "recipe_ratings[(recipe_ratings['protein'] > 200) | (recipe_ratings['carbohydrates'] > 200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_K9OoPJK5BJa"
   },
   "source": [
    "These rows have proportionally high calories, meaning this is unlikely to be an error and could just be because of large portion sizes. We can leave it as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_eH58cA5BJb"
   },
   "source": [
    "We want to account for the percentge of calories that the protein and carbohydrate contribute to. We will define high carbohydrate - low protein recipes using arbitrary cutoffs, considering those in the top 25th percentile of carb percentage and bottom 25th percentile of protein percentage. Using percentiles ensures that we select recipes that are high-carb in absolute terms and low-protein in absolute terms. This guarantees that the selected recipes are truly high in carbohydrate content and low in protein content, rather than just having a high ratio.\n",
    "\n",
    "To do this, we first need to convert protein and carbohydrate to calories. Each gram of carbohydrate or protein contains 4 calories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8z7PlD7E5BJi"
   },
   "outputs": [],
   "source": [
    "carb_calories = recipe_ratings['carbohydrates'] * 4  # 4 calories per gram of carbs\n",
    "protein_calories = recipe_ratings['protein'] * 4  # 4 calories per gram of protein\n",
    "\n",
    "recipe_ratings['carb_prop'] = carb_calories / recipe_ratings['calories']\n",
    "recipe_ratings['protein_prop'] = protein_calories / recipe_ratings['calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewgXzIAH5BJi"
   },
   "outputs": [],
   "source": [
    "carb_threshold = recipe_ratings['carb_prop'].quantile(0.75)\n",
    "protein_threshold = recipe_ratings['protein_prop'].quantile(0.25)\n",
    "\n",
    "recipe_ratings['high_carb_low_protein'] = (\n",
    "    (recipe_ratings['carb_prop'] >= carb_threshold) &\n",
    "    (recipe_ratings['protein_prop'] <= protein_threshold)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "031I0K9s5BJi"
   },
   "outputs": [],
   "source": [
    "recipe_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.concat([original_df, recipe_ratings[['carb_prop', 'protein_prop', 'high_carb_low_protein']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN3SyBh-5BJi"
   },
   "source": [
    "We can see that protein_percent has a max value of 1.88 which is not possible, indicating an error. We will drop all such rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTXz0-Q65BJi"
   },
   "outputs": [],
   "source": [
    "recipe_ratings = recipe_ratings[(recipe_ratings['protein_prop'] <= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = original_df[(original_df['protein_prop'] <= 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWjXZT0x5BJi"
   },
   "source": [
    "Now we are ready to visualize our features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3ZrAsa65BJi"
   },
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASnvJ17L5BJi"
   },
   "outputs": [],
   "source": [
    "# import plotly.io as pio\n",
    "# pio.renderers.default = \"browser\"  # IGNORE THIS FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2fS2UPv5BJi"
   },
   "outputs": [],
   "source": [
    "#Distribution of Ratings\n",
    "fig1 = px.histogram(recipe_ratings, x='avg_rating', nbins=10, title='Distribution of Average Recipe Ratings')\n",
    "# fig1.write_html(\"assets/avg_rating_histogram.html\", include_plotlyjs=\"cdn\")\n",
    "\n",
    "# Create and save the second histogram\n",
    "fig2 = px.histogram(recipe_ratings, x='protein_prop', nbins=10, title='Distribution of Protein Proportion in Recipes')\n",
    "fig2.write_html(\"/Users/johnwesleypabalate/Desktop/recipe-rating-analysis/assets/protein_prop_histogram.html\", include_plotlyjs=\"cdn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB7zEcIM5BJi"
   },
   "source": [
    "The distribution of average ratings is **highly skewed to the left**.This suggests that most recipes receive **high ratings**, making it important to analyze which rating values appear most frequently and how they relate to other factors like the nutritional facts of the food."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoaXfx7l5BJi"
   },
   "source": [
    "Most ratings left by people tend to be 5 stars.\n",
    "\n",
    "Now let's look at the distribution of Carbohydrate and Protein content of recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZF0PIws5BJi"
   },
   "outputs": [],
   "source": [
    "recipe_ratings['protein'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOlbDR7U5BJj"
   },
   "outputs": [],
   "source": [
    "recipe_ratings['carbohydrates'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xmbDofD5BJj"
   },
   "source": [
    "There appears to be very high values of carb and protein (over 3000) which seems unrealistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ItDNtCS5BJj"
   },
   "outputs": [],
   "source": [
    "fig_protein = px.box(recipe_ratings, x='protein', title='Boxplot of Protein Content')\n",
    "fig_protein.show()\n",
    "\n",
    "fig_carbs = px.box(recipe_ratings, x='carbohydrates', title='Boxplot of Carbohydrates Content')\n",
    "fig_carbs.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEDh4nKP5BJj"
   },
   "outputs": [],
   "source": [
    "recipe_ratings[(recipe_ratings['carbohydrates'] > 200) | (recipe_ratings['carbohydrates'] > 200)].shape[0] / recipe_ratings.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyFfyiBO5BJj"
   },
   "source": [
    "Less than 0.3 % of the data has either protein or carbohydrate content over 200g, so we can leave the outliers as they are since they are not likely to affect our analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLH8dIFE5BJj"
   },
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tv2PzMT45BJj"
   },
   "outputs": [],
   "source": [
    "px.scatter(recipe_ratings, x=\"avg_rating\", y=\"carbohydrates\",\n",
    "                 title=\"Carbohydrates vs. Ratings\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUJKkh8f5BJj"
   },
   "outputs": [],
   "source": [
    "px.scatter(recipe_ratings, x=\"avg_rating\", y=\"protein\",\n",
    "                 title=\"Protein vs. Ratings\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected scatter plots using proportions\n",
    "fig1 = px.scatter(recipe_ratings, x=\"avg_rating\", y=\"carb_prop\",\n",
    "                  title=\"Carbohydrate Proportion vs. Ratings\",\n",
    "                  opacity=0.5)\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.scatter(recipe_ratings, x=\"avg_rating\", y=\"protein_prop\",\n",
    "                  title=\"Protein Proportion vs. Ratings\",\n",
    "                  opacity=0.5)\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(recipe_ratings, x=\"avg_rating\", y=\"carb_prop\",\n",
    "                         title=\"Heatmap of Carbohydrate Proportion vs. Ratings\",\n",
    "                         nbinsx=10, nbinsy=30, color_continuous_scale=\"Blues\")  # Increase bins\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(recipe_ratings, x=\"avg_rating\", y=\"protein_prop\",\n",
    "                         title=\"Heatmap of Carbohydrate Proportion vs. Ratings\",\n",
    "                         nbinsx=10, nbinsy=30, color_continuous_scale=\"Blues\")  # Increase bins\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.box(recipe_ratings, x=\"avg_rating\", y=\"carb_prop\",\n",
    "              title=\"Carbohydrate Proportion by Ratings\",\n",
    "              labels={\"avg_rating\": \"Average Rating\", \"carb_prop\": \"Carbohydrate Proportion\"})\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.box(recipe_ratings, x=\"avg_rating\", y=\"protein_prop\",\n",
    "              title=\"Protein Proportion by Ratings\",\n",
    "              labels={\"avg_rating\": \"Average Rating\", \"protein_prop\": \"Protein Proportion\"})\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting Aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semething interesting to see would be if carbohydrate and protein content vary by how long it takes to make a recipe. Do shorter recipes tend to be carb-heavy while longer recipes are more balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ratings['cooking_time_category'] = pd.cut(recipe_ratings['minutes'], \n",
    "                                                 bins=[0, 30, 60, 120, recipe_ratings['minutes'].max()], \n",
    "                                                 labels=['<30 min', '30-60 min', '60-120 min', '120+ min'],\n",
    "                                                 include_lowest=True)\n",
    "\n",
    "agg_cooking_time = recipe_ratings.groupby('cooking_time_category').agg(\n",
    "    avg_rating=('avg_rating', 'mean'),\n",
    "    avg_carb_prop=('carb_prop', 'mean'),\n",
    "    avg_protein_prop=('protein_prop', 'mean'),\n",
    "    count=('recipe_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "agg_cooking_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(agg_cooking_time, x='cooking_time_category', y=['avg_carb_prop', 'avg_protein_prop'],\n",
    "             title='Average Macronutrient Proportions by Cooking Time Category',\n",
    "             labels={'value': 'Proportion', 'cooking_time_category': 'Cooking Time Category'},\n",
    "             barmode='group')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it looks like the carbohydrate content stays around the same through dfferent cooking time categories, but protein content seems to increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXnBYdA25BJj"
   },
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    },
    "id": "a2f7wO9d5BJj"
   },
   "outputs": [],
   "source": [
    "# merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0jd6L6XARPq"
   },
   "outputs": [],
   "source": [
    "# Define missingness indicator for \"review\"\n",
    "merged_df[\"review_missing\"] = merged_df[\"review\"].isnull()\n",
    "\n",
    "# Number of repetitions\n",
    "n_repetitions = 500\n",
    "shuffled = merged_df.copy()\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "\n",
    "    # Shuffling the missingness indicator for 'review'\n",
    "    shuffled[\"review_missing\"] = np.random.permutation(shuffled[\"review_missing\"])\n",
    "\n",
    "    # Computing and storing the TVD\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index=\"rating\", columns=\"review_missing\", aggfunc=\"size\")\n",
    "    )\n",
    "\n",
    "    pivoted = pivoted / pivoted.sum()\n",
    "\n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)\n",
    "\n",
    "# Compute observed TVD\n",
    "observed_pivot = merged_df.pivot_table(index=\"rating\", columns=\"review_missing\", aggfunc=\"size\")\n",
    "observed_pivot = observed_pivot / observed_pivot.sum()\n",
    "observed_tvd = observed_pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "\n",
    "# Create a histogram of TVD values\n",
    "fig = px.histogram(pd.DataFrame(tvds), x=0, nbins=50, histnorm=\"probability\",\n",
    "                   title=\"Empirical Distribution of the TVD\")\n",
    "\n",
    "# Add observed TVD as a red vertical line\n",
    "fig.add_vline(x=observed_tvd, line_color=\"red\", line_width=2, opacity=1)\n",
    "\n",
    "# Add annotation for observed TVD\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 2)}</span>',\n",
    "                   x=2.5 * observed_tvd, showarrow=False, y=0.16)\n",
    "\n",
    "# Adjust axis range\n",
    "fig.update_layout(yaxis_range=[0, 0.2])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8So0-z9mHECo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.array(tvds) >= observed_tvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqgHuVbOcohw"
   },
   "source": [
    "We **fail to reject the null**.\n",
    "This test does not provide evidence that the missingness in the 'review' column is dependent on 'rating' since 0.69 > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBl1jSeDIaO1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df[\"review_missing\"] = merged_df[\"review\"].isnull()\n",
    "\n",
    "# Number of repetitions\n",
    "n_repetitions = 500\n",
    "shuffled = merged_df.copy()\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "\n",
    "    # Shuffling the missingness indicator for 'review'\n",
    "    shuffled[\"review_missing\"] = np.random.permutation(shuffled[\"review_missing\"])\n",
    "\n",
    "    # Computing and storing the TVD\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index=\"n_steps\", columns=\"review_missing\", aggfunc=\"size\")\n",
    "    )\n",
    "\n",
    "    pivoted = pivoted / pivoted.sum()\n",
    "\n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)\n",
    "\n",
    "# Compute observed TVD\n",
    "observed_pivot = merged_df.pivot_table(index=\"n_steps\", columns=\"review_missing\", aggfunc=\"size\")\n",
    "observed_pivot = observed_pivot / observed_pivot.sum()\n",
    "observed_tvd = observed_pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "\n",
    "# Compute p-value\n",
    "p_value = np.mean(np.array(tvds) >= observed_tvd)\n",
    "\n",
    "# Create a histogram of TVD values\n",
    "fig = px.histogram(pd.DataFrame(tvds), x=0, nbins=50, histnorm=\"probability\",\n",
    "                   title=\"Empirical Distribution of the TVD for n_steps\")\n",
    "\n",
    "# Add observed TVD as a red vertical line\n",
    "fig.add_vline(x=observed_tvd, line_color=\"red\", line_width=2, opacity=1)\n",
    "\n",
    "# Add annotation for observed TVD\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 2)}</span>',\n",
    "                   x=2.5 * observed_tvd, showarrow=False, y=0.16)\n",
    "\n",
    "# Adjust axis range\n",
    "fig.update_layout(yaxis_range=[0, 0.2])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSxTj0KWLTKG"
   },
   "outputs": [],
   "source": [
    "np.mean(np.array(tvds) >= observed_tvd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"rate_missing\"] = merged_df[\"rating\"].isnull()\n",
    "\n",
    "# Number of repetitions\n",
    "n_repetitions = 500\n",
    "shuffled = merged_df.copy()\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "\n",
    "    # Shuffling the missingness indicator for 'review'\n",
    "    shuffled[\"rate_missing\"] = np.random.permutation(shuffled[\"rate_missing\"])\n",
    "\n",
    "    # Computing and storing the TVD\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index=\"n_steps\", columns=\"rate_missing\", aggfunc=\"size\")\n",
    "    )\n",
    "\n",
    "    pivoted = pivoted / pivoted.sum()\n",
    "\n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)\n",
    "\n",
    "# Compute observed TVD\n",
    "observed_pivot = merged_df.pivot_table(index=\"n_steps\", columns=\"rate_missing\", aggfunc=\"size\")\n",
    "observed_pivot = observed_pivot / observed_pivot.sum()\n",
    "observed_tvd = observed_pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "\n",
    "# Compute p-value\n",
    "p_value = np.mean(np.array(tvds) >= observed_tvd)\n",
    "\n",
    "# Create a histogram of TVD values\n",
    "fig = px.histogram(pd.DataFrame(tvds), x=0, nbins=50, histnorm=\"probability\",\n",
    "                   title=\"Empirical Distribution of the TVD for n_steps\")\n",
    "\n",
    "# Add observed TVD as a red vertical line\n",
    "fig.add_vline(x=observed_tvd, line_color=\"red\", line_width=2, opacity=1)\n",
    "\n",
    "# Add annotation for observed TVD\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 2)}</span>',\n",
    "                   x=2.5 * observed_tvd, showarrow=False, y=0.16)\n",
    "\n",
    "# Adjust axis range\n",
    "fig.update_layout(yaxis_range=[0, 0.2])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"rate_missing\"] = merged_df[\"rating\"].isnull()\n",
    "\n",
    "# Number of repetitions\n",
    "n_repetitions = 500\n",
    "shuffled = merged_df.copy()\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "\n",
    "    # Shuffling the missingness indicator for 'review'\n",
    "    shuffled[\"rate_missing\"] = np.random.permutation(shuffled[\"rate_missing\"])\n",
    "\n",
    "    # Computing and storing the TVD\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index=\"description\", columns=\"rate_missing\", aggfunc=\"size\")\n",
    "    )\n",
    "\n",
    "    pivoted = pivoted / pivoted.sum()\n",
    "\n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)\n",
    "\n",
    "# Compute observed TVD\n",
    "observed_pivot = merged_df.pivot_table(index=\"description\", columns=\"rate_missing\", aggfunc=\"size\")\n",
    "observed_pivot = observed_pivot / observed_pivot.sum()\n",
    "observed_tvd = observed_pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "\n",
    "# Compute p-value\n",
    "p_value = np.mean(np.array(tvds) >= observed_tvd)\n",
    "\n",
    "# Create a histogram of TVD values\n",
    "fig = px.histogram(pd.DataFrame(tvds), x=0, nbins=50, histnorm=\"probability\",\n",
    "                   title=\"Empirical Distribution of the TVD for n_steps\")\n",
    "\n",
    "# Add observed TVD as a red vertical line\n",
    "fig.add_vline(x=observed_tvd, line_color=\"red\", line_width=2, opacity=1)\n",
    "\n",
    "# Add annotation for observed TVD\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 2)}</span>',\n",
    "                   x=2.5 * observed_tvd, showarrow=False, y=0.16)\n",
    "\n",
    "# Adjust axis range\n",
    "fig.update_layout(yaxis_range=[0, 0.2])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **reject the null**.\n",
    "This test provide evidence that the missingness in the 'review' column is dependent on 'n_steps' since 0.118 < 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5jz5OK_5BJj"
   },
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    },
    "id": "Af50wpNv5BJj"
   },
   "source": [
    "Our goal is to see if carbohydrate and protein content affect ratings of recipes. We define high-carb, low-protein recipes as those that fall into both:\n",
    "\n",
    "- The top 25th percentile for the proportion of calories from carbohydrates\n",
    "- The bottom 25th percentile for the proportion of calories from protein\n",
    "\n",
    "**Null Hypothesis (H₀):** Recipes with high carb % and low protein % receive the same ratings as other recipes.  \n",
    "\n",
    "**Alternative Hypothesis (Hₐ):** Recipes with high carb % and low protein % receive significantly different ratings.\n",
    "\n",
    "**Test statistic:** Mean difference in ratings between the high-carb, low-protein group and others.\n",
    "\n",
    "**Significance level:** 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uh3EkZhz5BJk"
   },
   "outputs": [],
   "source": [
    "observed_diff = recipe_ratings.groupby(\"high_carb_low_protein\")[\"avg_rating\"].mean().diff().iloc[-1]\n",
    "\n",
    "def permute_ratings(df):\n",
    "    shuffled = df[\"avg_rating\"].sample(frac=1, replace=False).reset_index(drop=True)\n",
    "    df[\"shuffled_rating\"] = shuffled\n",
    "    return df.groupby(\"high_carb_low_protein\")[\"shuffled_rating\"].mean().diff().iloc[-1]\n",
    "\n",
    "perm_diffs = [permute_ratings(recipe_ratings) for _ in range(1000)]\n",
    "\n",
    "p_value = np.mean(np.array(perm_diffs) >= observed_diff)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu58Fbil5BJk"
   },
   "source": [
    "Since the p-value is less than the significance level 0.05, we reject the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sjd_PyAb5BJk"
   },
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict the ratings of recipes using different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cOT86D45BJk"
   },
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    },
    "id": "J9qQ5IVh5BJk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use all data we have engineered along with the original provided data. We have been keeping track of this in `original_df` so we will use this dataframe for our modeling. Let us first create some new features of interest:\n",
    "\n",
    "`'steps_per_minute'`: We will create this column to put into perspective the number of steps required for the duration of a recipe. This tells us whether it requires higher effort (having to perform several steps quickly). Effort may be related to how a recipe is rated. We will use this for our final analysis.\n",
    "\n",
    "Let us also convert 'high_carb_low_protein' columnn into a binary column to make our analyses easier. We will then drop all null values so that they dont affect the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_df['steps_per_minute'] = original_df['n_steps'] / (original_df['minutes'] + 1e-6)\n",
    "original_df['high_carb_low_protein'] = original_df['high_carb_low_protein'].astype(int)\n",
    "original_df = original_df.dropna()\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our baseline model, we will use 'minutes' (quantitative, numerical), 'n_ingredients'(quantitative, numerical) and 'high_carb_low_protein'(quantitative, nominal) in a Random Forest Regressor model to predict 'avg_rating'. \n",
    "\n",
    "We want to use these features because we believe the recipes that take very long may get lower ratings while higher number of ingredients may make the recipe more complex and taste better, receiving higher ratings. From our previous analyses we saw that high carb, low protein recipes tend to get higher ratings, so we beleive these would be a good predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize the quantitative features using StandardScaler to ensure they are on a comparable scale. The categorical feature is left as-is since it is already binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = ['minutes', 'n_ingredients', 'high_carb_low_protein']\n",
    "final_features = ['high_carb_low_protein', 'steps_per_minute', 'carb_prop', 'protein_prop']\n",
    "\n",
    "y = original_df['avg_rating'] \n",
    "X = original_df.drop(columns=['avg_rating', 'rating']) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_baseline = X_train[baseline_features]\n",
    "X_test_baseline = X_test[baseline_features]\n",
    "X_train_final = X_train[final_features]\n",
    "X_test_final = X_test[final_features]\n",
    "\n",
    "preprocessor_baseline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), ['minutes', 'n_ingredients']) \n",
    "], remainder='passthrough')\n",
    "\n",
    "preprocessor_final = ColumnTransformer([\n",
    "    ('num', StandardScaler(), ['steps_per_minute', 'carb_prop', 'protein_prop']),  \n",
    "], remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_baseline),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))  \n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(X_train_baseline, y_train)\n",
    "\n",
    "y_pred_baseline = baseline_pipeline.predict(X_test_baseline)\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"Baseline MAE: {mae_baseline:.4f}\")\n",
    "print(f\"Baseline R²: {r2_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHifXL6O5BJk"
   },
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final model, we will use more nutrition related features, since they might be more likely to affect quality of food and hence the ratings:\n",
    "'high_carb_low_protein'(quantitative, nominal), 'steps_per_minute'(quantitative, numerical), 'carb_prop'(quantitative, numerical), 'protein_prop'(quantitative, numerical).\n",
    "We standardize the numerical features using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_final),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [5, 10, 15],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search_final = RandomizedSearchCV(\n",
    "    final_pipeline, param_distributions=param_dist, n_iter=10,\n",
    "    cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\n Running Final Model Hyperparameter Search...\")\n",
    "random_search_final.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred_final = random_search_final.best_estimator_.predict(X_test_final)\n",
    "mae_final = mean_absolute_error(y_test, y_pred_final)\n",
    "r2_final = r2_score(y_test, y_pred_final)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", random_search_final.best_params_)\n",
    "print(f\"Final Model MAE: {mae_final:.4f}\")\n",
    "print(f\"Final Model R²: {r2_final:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that MAE reduced and R² increased. This means that our final model improved. Below, we can see what the most important features were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search_final.best_estimator_\n",
    "feature_importance = best_model.named_steps['model'].feature_importances_\n",
    "final_feature_names = best_model[:-1].get_feature_names_out()\n",
    "\n",
    "print(\"Extracted Features:\", final_feature_names)\n",
    "print(\"Feature Importance Length:\", len(feature_importance))\n",
    "\n",
    "clean_feature_names = [name.replace(\"num__\", \"\").replace(\"remainder__\", \"\") for name in final_feature_names]\n",
    "\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': clean_feature_names,  \n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    importance_df, \n",
    "    x='Importance', \n",
    "    y='Feature', \n",
    "    text=importance_df['Importance'].round(4), \n",
    "    title=\"Feature Importance in Final Model\"\n",
    ")\n",
    "fig.update_traces(marker_color='royalblue', textposition='outside')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36EDTNsf5BJk"
   },
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    },
    "id": "Af50wpNv5BJj"
   },
   "source": [
    "The goal of this analysis is to determine whether our model exhibits bias in predicting recipe ratings based on the carb proportion (carb_prop) in a recipe. We split recipes into two groups:\n",
    "\n",
    "High-carb recipes: Those with a carb_prop greater than the mean.\n",
    "Low-carb recipes: Those with a carb_prop less than or equal to the mean.\n",
    "We evaluate whether the model's performance (Mean Absolute Error, MAE) differs significantly between these two groups.\n",
    "\n",
    "\n",
    "**Null Hypothesis:** The model is fair. Its MAE for high-carb and low-carb recipes is roughly the same, and any differences are due to random chance.\n",
    "\n",
    "**Alternative Hypothesis:** The model is unfair. It performs significantly better (lower MAE) for low-carb recipes compared to high-carb recipes.\n",
    "\n",
    "**Significance level:** 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_carb = X_test['carb_prop'].mean()\n",
    "is_high_carb = X_test['carb_prop'] > mean_carb\n",
    "\n",
    "y_test_high = y_test[is_high_carb]\n",
    "y_pred_high = y_pred_final[is_high_carb]\n",
    "mae_high = mean_absolute_error(y_test_high, y_pred_high)\n",
    "\n",
    "y_test_low = y_test[~is_high_carb]\n",
    "y_pred_low = y_pred_final[~is_high_carb]\n",
    "mae_low = mean_absolute_error(y_test_low, y_pred_low)\n",
    "\n",
    "observed_diff = mae_low - mae_high\n",
    "print(f\"Mean carb_prop: {mean_carb:.4f}\")\n",
    "print(f\"MAE for high carb_prop recipes: {mae_high:.4f}\")\n",
    "print(f\"MAE for low carb_prop recipes: {mae_low:.4f}\")\n",
    "print(f\"Observed difference in MAE (low - high): {observed_diff:.4f}\")\n",
    "\n",
    "n_permutations = 1000\n",
    "diff_permutations = []\n",
    "is_high_carb_array = is_high_carb.values.copy()\n",
    "for _ in range(n_permutations):\n",
    "    np.random.shuffle(is_high_carb_array)\n",
    "    \n",
    "    mae_high_perm = mean_absolute_error(y_test[is_high_carb_array], y_pred_final[is_high_carb_array])\n",
    "    mae_low_perm = mean_absolute_error(y_test[~is_high_carb_array], y_pred_final[~is_high_carb_array])\n",
    "    \n",
    "    diff_permutations.append(mae_low_perm - mae_high_perm)\n",
    "\n",
    "\n",
    "p_value = np.mean([diff <= observed_diff for diff in diff_permutations])  # Test if low carb has lower MAE\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(diff_permutations, bins=30, alpha=0.7, color='blue')\n",
    "plt.axvline(observed_diff, color='red', linestyle='--', label='Observed statistic')\n",
    "plt.title('Empirical Distribution of the Difference in MAE (Low Carb - High Carb)')\n",
    "plt.xlabel('Difference in MAE')  \n",
    "plt.ylabel('Frequency')  \n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The model performs significantly better for recipes with low carb_prop.\")\n",
    "else:\n",
    "    print(\"No significant evidence that the model performs better for low carb recipes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
